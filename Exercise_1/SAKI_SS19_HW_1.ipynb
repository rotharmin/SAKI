{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAKI SS19  Homework 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import time\n",
    "import datetime\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc,roc_auc_score, classification_report, confusion_matrix\n",
    "from nltk.stem.cistem import Cistem\n",
    "from schwifty import IBAN,BIC\n",
    "from sklearn.preprocessing import label_binarize, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "df = pd.read_csv(\"./Exercise 1 - Transaction Classification - Data Set.csv\",sep=';',index_col=0, encoding='utf8',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:\n",
      "(209, 11)\n",
      "\n",
      "features and types:\n",
      "Auftragskonto                        float64\n",
      "Buchungstag                           object\n",
      "Valutadatum                           object\n",
      "Buchungstext                          object\n",
      "Verwendungszweck                      object\n",
      "Beguenstigter/Zahlungspflichtiger     object\n",
      "Kontonummer                           object\n",
      "BLZ                                   object\n",
      "Betrag                                object\n",
      "Waehrung                              object\n",
      "label                                 object\n",
      "dtype: object\n",
      "\n",
      "is null:\n",
      "Auftragskonto                        41\n",
      "Buchungstag                           0\n",
      "Valutadatum                           0\n",
      "Buchungstext                          0\n",
      "Verwendungszweck                      0\n",
      "Beguenstigter/Zahlungspflichtiger     0\n",
      "Kontonummer                           1\n",
      "BLZ                                   1\n",
      "Betrag                                0\n",
      "Waehrung                              0\n",
      "label                                 0\n",
      "dtype: int64\n",
      "\n",
      "class names:\n",
      "['income' 'living' 'private' 'standardOfLiving' 'leisure' 'finance']\n",
      "\n",
      "class frequencies:\n",
      "leisure             65\n",
      "standardOfLiving    47\n",
      "finance             33\n",
      "living              26\n",
      "private             21\n",
      "income              17\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# # # # # # # # # #\n",
    "# gather some information about dataset\n",
    "# # # # # # # # # #\n",
    "\n",
    "print('shape:')\n",
    "print(df.shape)\n",
    "print('\\nfeatures and types:')\n",
    "print(df.dtypes)\n",
    "print('\\nis null:')\n",
    "print(df.isnull().sum())\n",
    "print('\\nclass names:')\n",
    "print(pd.unique(df.label))\n",
    "print('\\nclass frequencies:')\n",
    "print(df.label.value_counts())\n",
    "#df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # # # # #\n",
    "# prepare Data in general\n",
    "# # # # # # # # # #\n",
    "\n",
    "#fill null Values with \"0\"\n",
    "df=df.fillna(0)\n",
    "\n",
    "#Convert Datatypes\n",
    "\n",
    "df['Kontonummer'] = df['Kontonummer'].astype('str')\n",
    "df['BLZ'] = df['BLZ'].astype('str')\n",
    "df['Buchungstag'] = pd.to_datetime(df['Buchungstag'])\n",
    "df['Betrag'] = [x.replace(',', '.') for x in df['Betrag']]\n",
    "df['Betrag'] = df['Betrag'].astype('float')\n",
    "#df['Auftragskonto'] = df['Auftragskonto'].astype('int')\n",
    "#df['Valutadatum'] = pd.to_datetime(df['Valutadatum'])\n",
    "\n",
    "#drop unused columns (low variance or duplicates)\n",
    "df=df.drop(['Auftragskonto','Waehrung','Valutadatum'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # # # # #\n",
    "# standardize bankaccount\n",
    "# # # # # # # # # #\n",
    "\n",
    "def perpare_bankaccount(kontonummer,blz):\n",
    "    if(len(kontonummer)==0):\n",
    "        return ''\n",
    "    if(len(kontonummer)!=22):\n",
    "        if(len(blz)>8):\n",
    "            blz=BIC(blz).country_bank_code\n",
    "        kontonummer = IBAN.generate('DE', bank_code=blz, account_code=kontonummer)\n",
    "    return str(kontonummer)\n",
    "\n",
    "#kontonummer vereinlichen\n",
    "df['iban']=df.apply(lambda x: perpare_bankaccount(kontonummer=x['Kontonummer'],blz=x['BLZ']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # # # # #\n",
    "# prepare text features\n",
    "# # # # # # # # # #\n",
    "\n",
    "def prepare_text(text):\n",
    "    #convert all text to lower case\n",
    "    text = text.lower()\n",
    "    #remove punctuation \n",
    "    table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    #table = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(table)\n",
    "    #table = str.maketrans('', '', string.digits)\n",
    "    #text = text.translate(table)\n",
    "    #tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    #remove stop words\n",
    "    for token in tokens:\n",
    "        if token in stopwords.words('german'):\n",
    "            tokens.remove(token)\n",
    "    #stemming\n",
    "    #stemmer=Cistem()\n",
    "   # for i in range(len(tokens)):\n",
    "   #     tokens[i] = stemmer.stem(tokens[i])\n",
    "    #spell correction\n",
    "    return \" \".join(tokens)\n",
    "    #return pd.concat(tokens)\n",
    "        \n",
    "def vectorize_transform(prepared_text):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(prepared_text).toarray()\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_tfidf = tfidf_transformer.fit_transform(X).toarray()\n",
    "    topics = vectorizer.get_feature_names()\n",
    "    return pd.DataFrame(data=X_tfidf, columns=topics)\n",
    "    #return X_tfidf\n",
    "    \n",
    "def vectorize(prepared_text):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(prepared_text).toarray()\n",
    "    topics = vectorizer.get_feature_names()\n",
    "    return pd.DataFrame(data=X, columns=topics)\n",
    "    \n",
    "def k_best(x,y,k):\n",
    "    selector=SelectKBest(chi2, k=k)\n",
    "    x_new=selector.fit_transform(x,y)\n",
    "    columns = selector.get_support(indices=True)\n",
    "    new_columns = x.columns[columns]\n",
    "    return pd.DataFrame(x_new,columns=new_columns)\n",
    "\n",
    "\n",
    "#tokenize\n",
    "Verwendungszweck_tokenized = df['Verwendungszweck'].apply(prepare_text)\n",
    "Buchungstext_tokenized = df['Buchungstext'].apply(prepare_text)\n",
    "\n",
    "#vecorize/transform\n",
    "df_verwendungszweck=vectorize_transform(Verwendungszweck_tokenized)\n",
    "df_buchungstext=vectorize_transform(Buchungstext_tokenized)\n",
    "df_iban=vectorize(df['iban'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # # # # #\n",
    "# prepare betrag\n",
    "# # # # # # # # # #\n",
    "\n",
    "#Normalize values\n",
    "x = df[['Betrag']].values\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_betrag = pd.DataFrame(x_scaled, columns=['Betrag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 228)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # # # # # # # # #\n",
    "# assambling final test/train dataset \n",
    "# # # # # # # # # #\n",
    "\n",
    "#drop unnaccesary columns\n",
    "#df=df.drop(['Auftragskonto','Waehrung','Betrag','Valutadatum','Buchungstag'],axis=1)\n",
    "y=df['label']\n",
    "df_final = pd.concat([k_best(df_verwendungszweck,y,160),df_iban,df_buchungstext,df_betrag],axis=1)\n",
    "\n",
    "#drop duplicated columns\n",
    "df_final = df_final.loc[:,~df_final.columns.duplicated()]\n",
    "df_final.shape\n",
    "#y = label_binarize(y, classes=['income', 'living', 'private', 'standardOfLiving', 'leisure', 'finance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9682539682539683\n",
      "\n",
      "Details: \n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         finance       1.00      1.00      1.00        12\n",
      "          income       1.00      1.00      1.00         7\n",
      "         leisure       0.89      1.00      0.94        16\n",
      "          living       1.00      0.80      0.89         5\n",
      "         private       1.00      1.00      1.00         8\n",
      "standardOfLiving       1.00      0.93      0.97        15\n",
      "\n",
      "       micro avg       0.97      0.97      0.97        63\n",
      "       macro avg       0.98      0.96      0.97        63\n",
      "    weighted avg       0.97      0.97      0.97        63\n",
      "\n",
      "Confusion matrix:\n",
      "                       pre:fin  pre:lei  pre:sta  pre:liv  pre:pri  pre:inc\n",
      "true:finance                12        0        0        0        0        0\n",
      "true:leisure                 0       16        0        0        0        0\n",
      "true:standardOfLiving        0        1       14        0        0        0\n",
      "true:living                  0        1        0        4        0        0\n",
      "true:private                 0        0        0        0        8        0\n",
      "true:income                  0        0        0        0        0        7\n"
     ]
    }
   ],
   "source": [
    "# # # # # # # # # #\n",
    "#Training the classifier and evaluation\n",
    "# # # # # # # # # #\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_final, y, test_size=0.3,random_state=1)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df_final, y, test_size=0.3,random_state=int(time.time()))\n",
    "\n",
    "#gausian naive bayes\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Train classifier\n",
    "gnb.fit(X_train,y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "y_pred_proba=gnb.predict_proba(X_test)\n",
    "\n",
    "#evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: ' + str(accuracy) + '\\n')\n",
    "print('Details: \\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Confusion matrix:')\n",
    "unique_label = pd.unique(y_test)\n",
    "#print(confusion_matrix(y_test, y_pred,labels=unique_label))\n",
    "\n",
    "print(pd.DataFrame(confusion_matrix(y_test, y_pred, labels=unique_label), \n",
    "                   index=['true:{:}'.format(x) for x in unique_label], \n",
    "                   columns=['pre:{:}'.format(x[:3]) for x in unique_label]))\n",
    "\n",
    "\n",
    "\n",
    "#roc_auc_score(y_test,y_pred_proba)\n",
    "#fpr, tpr, threshold = roc_curve(y_test, y_pred)\n",
    "#roc_auc = auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
